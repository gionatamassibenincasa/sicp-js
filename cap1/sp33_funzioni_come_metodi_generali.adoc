[[sec:proc-general-methods]]
==== Functions as General Methods

We introduced compound functions in section [sec:compound-procedures] as a mechanism for abstracting patterns of numerical operations so as to make them independent of the particular numbers involved. With higher-order functions, such as the `integral` function of section [sec:procedures-as-parameters], we began to see a more powerful kind of abstraction: functions used to express general methods of computation, independent of the particular functions involved. In this section we discuss two more elaborate examples—general methods for finding zeros and fixed points of functions—and show how these methods can be expressed directly as functions.

[[finding-roots-of-equations-by-the-half-interval-method]]
===== Finding roots of equations by the half-interval method

The _half-interval method_ is a simple but powerful technique for finding roots of an equation latexmath:[$f(x)=0$], where latexmath:[$f$] is a continuous function. The idea is that, if we are given points latexmath:[$a$] and latexmath:[$b$] such that latexmath:[$f(a) < 0 < f(b)$], then latexmath:[$f$] must have at least one zero between latexmath:[$a$] and latexmath:[$b$]. To locate a zero, let latexmath:[$x$] be the average of latexmath:[$a$] and latexmath:[$b$] and compute latexmath:[$f(x)$]. If latexmath:[$f(x) > 0$], then latexmath:[$f$] must have a zero between latexmath:[$a$] and latexmath:[$x$]. If latexmath:[$f(x) < 0$], then latexmath:[$f$] must have a zero between latexmath:[$x$] and latexmath:[$b$]. Continuing in this way, we can identify smaller and smaller intervals on which latexmath:[$f$] must have a zero. When we reach a point where the interval is small enough, the process stops. Since the interval of uncertainty is reduced by half at each step of the process, the number of steps required grows as latexmath:[$\Theta(\log( L/T))$], where latexmath:[$L$] is the length of the original interval and latexmath:[$T$] is the error tolerance (that is, the size of the interval we will consider ``small enough''). Here is a function that implements this strategy:footnote:[Note that we slightly extend the syntax of conditional statements described in section [sec:lambda] by admitting another conditional statement in place of the block following `else`.]

....
function search(f, neg_point, pos_point) {
    const midpoint = average(neg_point,pos_point);
    if (close_enough(neg_point, pos_point)) {
        return midpoint;
    } else {
        const test_value = f(midpoint);
....

....
        if (positive(test_value)) {
            return search(f, neg_point, midpoint);
        } else if (negative(test_value)) {
            return search(f, midpoint, pos_point);
        } else {
            return midpoint;
        }
    }
}
....

We assume that we are initially given the function latexmath:[$f$] together with points at which its values are negative and positive. We first compute the midpoint of the two given points. Next we check to see if the given interval is small enough, and if so we simply return the midpoint as our answer. Otherwise, we compute as a test value the value of latexmath:[$f$] at the midpoint. If the test value is positive, then we continue the process with a new interval running from the original negative point to the midpoint. If the test value is negative, we continue with the interval from the midpoint to the positive point. Finally, there is the possibility that the test value is 0, in which case the midpoint is itself the root we are searching for. To test whether the endpoints are ``close enough'' we can use a function similar to the one used in section [sec:sqrt] for computing square roots:footnote:[We have used 0.001 as a representative ``small'' number to indicate a tolerance for the acceptable error in a calculation. The appropriate tolerance for a real calculation depends upon the problem to be solved and the limitations of the computer and the algorithm. This is often a very subtle consideration, requiring help from a numerical analyst or some other kind of magician.]

....
function close_enough(x,y) {
    return abs(x - y) < 0.001;
}
....

The function `search` is awkward to use directly, because we can accidentally give it points at which latexmath:[$f$]’s values do not have the required sign, in which case we get a wrong answer. Instead we will use `search` via the following function, which checks to see which of the endpoints has a negative function value and which has a positive value, and calls the `search` function accordingly. If the function has the same sign on the two given points, the half-interval method cannot be used, in which case the function signals an error.footnote:[This can be accomplished using `error`, which takes as argument a string that is printed as error message along with the number of the program line that gave rise to the call of `error`.]

....
function half_interval_method(f, a, b) {
    const a_value = f(a);
    const b_value = f(b);
    return negative(a_value) && positive(b_value)
           ? search(f, a, b)
           : negative(b_value) && positive(a_value)
....

....
             ? search(f, b, a)
             : error("values are not of opposite sign");
}
....

The following example uses the half-interval method to approximate latexmath:[$\pi$] as the root between 2 and 4 of latexmath:[$\sin\, x = 0$]:

....
half_interval_method(math_sin, 2.0, 4.0);
....

Here is another example, using the half-interval method to search for a root of the equation latexmath:[$x^3 - 2x - 3 = 0$] between 1 and 2:

....
half_interval_method(
  x => x * x * x - 2 * x - 3,
  1.0,
  2.0);
....

[[finding-fixed-points-of-functions]]
===== Finding fixed points of functions

A number latexmath:[$x$] is called a _fixed point_ of a function latexmath:[$f$] if latexmath:[$x$] satisfies the equation latexmath:[$f(x)=x$]. For some functions latexmath:[$f$] we can locate a fixed point by beginning with an initial guess and applying latexmath:[$f$] repeatedly, latexmath:[\[f(x), f(f(x)), f(f(f(x))), \ldots\]] until the value does not change very much. Using this idea, we can devise a function `fixed_point` that takes as inputs a function and an initial guess and produces an approximation to a fixed point of the function. We apply the function repeatedly until we find two successive values whose difference is less than some prescribed tolerance:

....
const tolerance = 0.00001;
function fixed_point(f, first_guess) {
    function close_enough(x, y) {
        return abs(x - y) < tolerance;
    }
    function try_with(guess) {
....

....
        const next = f(guess);
        return close_enough(guess, next)
               ? next
               : try_with(next);
    }
    return try_with(first_guess);
}
....

For example, we can use this method to approximate the fixed point of the cosine function, starting with 1 as an initial approximation:footnote:[Try this during a boring lecture: Set your calculator to radians mode and then repeatedly press the latexmath:[$\cos$] button until you obtain the fixed point.]

....
fixed_point(math_cos, 1.0);
....

Similarly, we can find a solution to the equation latexmath:[$y=\sin y + \cos y$]:

....
fixed_point(
    y => math_sin(y) + math_cos(y),
    1.0);
....

The fixed-point process is reminiscent of the process we used for finding square roots in section [sec:sqrt]. Both are based on the idea of repeatedly improving a guess until the result satisfies some criterion. In fact, we can readily formulate the square-root computation as a fixed-point search. Computing the square root of some number latexmath:[$x$] requires finding a latexmath:[$y$] such that latexmath:[$y^2 = x$]. Putting this equation into the equivalent form latexmath:[$y = x/y$], we recognize that we are looking for a fixed point of the functionfootnote:[latexmath:[$\mapsto$] (pronounced ``maps to'') is the mathematician’s way of writing lambda expressions. latexmath:[$y \mapsto x/y$] means `y => x / y`, that is, the function whose value at latexmath:[$y$] is latexmath:[$x/y$].] latexmath:[$y \mapsto x/y$], and we can therefore try to compute square roots as

....
function sqrt(x) {
    return fixed_point(y => x / y, 1.0);
}
....

Unfortunately, this fixed-point search does not converge. Consider an initial guess latexmath:[$y_1$]. The next guess is latexmath:[$y_2 = x/y_1$] and the next guess is latexmath:[$y_3 = x/y_2 = x/(x/y_1) = y_1$]. This results in an infinite loop in which the two guesses latexmath:[$y_1$] and latexmath:[$y_2$] repeat over and over, oscillating about the answer.

One way to control such oscillations is to prevent the guesses from changing so much. Since the answer is always between our guess latexmath:[$y$] and latexmath:[$x/y$], we can make a new guess that is not as far from latexmath:[$y$] as latexmath:[$x/y$] by averaging latexmath:[$y$] with latexmath:[$x/y$], so that the next guess after latexmath:[$y$] is latexmath:[$\frac{1}{2}(y+x/y)$] instead of latexmath:[$x/y$]. The process of making such a sequence of guesses is simply the process of looking for a fixed point of latexmath:[$y \mapsto \frac{1}{2}(y+x/y)$]:

....
function sqrt(x) {
    return fixed_point(
               y => average(y, x / y),
               1.0);
}
....

(Note that latexmath:[$y=\frac{1}{2}(y+x/y)$] is a simple transformation of the equation latexmath:[$y=x/y$]; to derive it, add latexmath:[$y$] to both sides of the equation and divide by 2.)

With this modification, the square-root function works. In fact, if we unravel the definitions, we can see that the sequence of approximations to the square root generated here is precisely the same as the one generated by our original square-root function of section [sec:sqrt]. This approach of averaging successive approximations to a solution, a technique we call , often aids the convergence of fixed-point searches.

[[ex:unlabeled14]]
Exercise
====
Show that the golden ratio latexmath:[$\phi$] (section [sec:tree-recursion]) is a fixed point of the transformation latexmath:[$x \mapsto 1 + 1/x$], and use this fact to compute latexmath:[$\phi$] by means of the `fixed_point` function.
====

////
[[solution]]
==== Solution

The fixed point of the function is latexmath:[\[1 + 1 / x = x\]] Solving for x, we get latexmath:[\[x^2 = x + 1\]] latexmath:[\[x^2 - x - 1 = 0\]] Using the quadratic equation to solve for latexmath:[$x$], we find that one of the roots of this equation is the golden ratio latexmath:[$(1+\sqrt{5})/2$].

....
fixed_point(x => 1 + (1 / x), 1.0);
....
////

[[exercise]]
Exercise
====
Modify `fixed_point` so that it prints the sequence of approximations it generates, using the primitive function `display` shown in exercise [ex:search-for-primes]. Then find a solution to latexmath:[$x^x = 1000$] by finding a fixed point of latexmath:[$x \mapsto \log(1000)/\log(x)$]. (Use the primitive function `math_log` which computes natural logarithms.) Compare the number of steps this takes with and without average damping. (Note that you cannot start `fixed_point` with a guess of 1, as this would cause division by latexmath:[$\log(1)=0$].) [ex:log-fixed-point]
====

////
[[solution-1]]
==== Solution

We modify the function `fixed_point` as follows:

....
const tolerance = 0.00001;
function fixed_point(f, first_guess) {
    function close_enough(x, y) {
        return abs(x - y) < tolerance;
    }
    function try_with(guess) {
....

....
        display(guess);
        const next = f(guess);
        return close_enough(guess, next)
               ? next
               : try_with(next);
    }
    return try_with(first_guess);
}
....

Here is a version with average dampening built-in:

....
function fixed_point_with_average_dampening(f, first_guess) {
    function close_enough(x, y) {
        return abs(x - y) < tolerance;
    }
    function try_with(guess) {
        display(guess);
....

....
        const next = (guess + f(guess)) / 2;
        return close_enough(guess, next)
               ? next
               : try_with(next);
    }
    return try_with(first_guess);
}
....
////

[[ex:continued-fractions]]
Exercise
====
* An infinite _continued fraction_ is an expression of the form latexmath:[\[f={\dfrac{N_1}{D_1+
          \dfrac{N_2}{D_2+
          \dfrac{N_3}{D_3+\cdots }}}}\]] As an example, one can show that the infinite continued fraction expansion with the latexmath:[$N_i$] and the latexmath:[$D_i$] all equal to 1 produces latexmath:[$1/\phi$], where latexmath:[$\phi$] is the golden ratio (described in section [sec:tree-recursion]). One way to approximate an infinite continued fraction is to truncate the expansion after a given number of terms. Such a truncation—a so-called _latexmath:[$k$]-term finite continued fraction_—has the form latexmath:[\[{\dfrac{N_1}{D_1 +
          \dfrac{N_2}{\ddots +
          \dfrac{N_K}{D_K}}}}\]] Suppose that `n` and `d` are functions of one argument (the term index latexmath:[$i$]) that return the latexmath:[$N_i$] and latexmath:[$D_i$] of the terms of the continued fraction. Declare a function `cont_frac` such that evaluating `cont_frac(n, d, k)` computes the value of the latexmath:[$k$]-term finite continued fraction. Check your function by approximating latexmath:[$1/\phi$] using
+
....
cont_frac(i => 1.0,
          i => 1.0,
          k);
....
+
for successive values of `k`. How large must you make `k` in order to get an approximation that is accurate to 4 decimal places?
* If your `cont_frac` function generates a recursive process, write one that generates an iterative process. If it generates an iterative process, write one that generates a recursive process.
====

////
[[solution-2]]
==== Solution

....
//recursive process
function cont_frac(n, d, k) {
    function fraction(i) {
        return i > k
               ? 0
               : n(i) / (d(i) + fraction(i + 1));
....

....
    }
    return fraction(1);
}
....

....
//iterative process
function cont_frac(n, d, k) {
    function fraction(i, current) {
        return i === 0
               ? current
               : fraction(i - 1, n(i) / (d(i) + current));
....

....
    }
    return fraction(k, 0);
}
....
////

[[ex:unlabeled15]]
.Exercise
====
In 1737, the Swiss mathematician Leonhard Euler published a memoir _De Fractionibus Continuis_, which included a continued fraction expansion for latexmath:[$e-2$], where latexmath:[$e$] is the base of the natural logarithms. In this fraction, the latexmath:[$N_i$] are all 1, and the latexmath:[$D_i$] are successively 1, 2, 1, 1, 4, 1, 1, 6, 1, 1, 8, …. Write a program that uses your `cont_frac` function from exercise [ex:continued-fractions] to approximate latexmath:[$e$], based on Euler’s expansion.
====

////
[[solution-3]]
==== Solution

....
2 + cont_frac(i => 1,  
              i => (i + 1) % 3 < 1 ? 2 * (i + 1) / 3 : 1,
              20);
....
////

[[ex:unlabeled16]]
.Exercise
====
A continued fraction representation of the tangent function was published in 1770 by the German mathematician J.H. Lambert: latexmath:[\[\tan x={\dfrac{x}{1-
      \dfrac{x^2}{3-
      \dfrac{x^2}{5-
      \dfrac{x^2}{ \ddots }}}}}\]] where latexmath:[$x$] is in radians. Declare a function `tan_cf(x, k)` that computes an approximation to the tangent function based on Lambert’s formula. As in exercise [ex:continued-fractions], `k` specifies the number of terms to compute.
====

////
[[solution-4]]
==== Solution

....
function tan_cf(x, k) {
    return cont_frac(i => i === 1 ? x : - x * x,  
                     i => 2 * i - 1,
                     k);
}
....
////

//